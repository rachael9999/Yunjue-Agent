BASIC_MODEL:
  # Qwen via DashScope (OpenAI-compatible mode)
  provider: qwen
  base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
  model: "qwen-plus"
  # Put your DashScope key here, or leave empty and export DASHSCOPE_API_KEY.
  api_key: ""
  temperature: 0.7
  token_limit: 200000
  # max_retries: 3
  # max_retries: 3 # Maximum number of retries for LLM calls


EVAL_MODEL:
  provider: qwen
  base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
  model: "qwen-plus"
  api_key: ""
  temperature: 0
  token_limit: 200000
  # max_retries: 3
  # max_retries: 3 # Maximum number of retries for LLM calls



VISION_MODEL:
  provider: qwen
  base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
  model: "qwen-vl-plus"
  api_key: ""
  temperature: 0.7
  token_limit: xxx
  # max_retries: 3
  # timeout: 180

SUMMARIZE_MODEL:
  provider: qwen
  base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
  model: "qwen-plus"
  api_key: ""
  temperature: 0.2
  token_limit: 200000
  # max_retries: 3 # Maximum number of retries for summary LLM calls
  # timeout: 180


CLUSTER_MODEL:
  provider: qwen
  base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
  model: "qwen-plus"
  api_key: ""
  temperature: 0.2
  token_limit: 200000
  # max_retries: 3 # Maximum number of retries for summary LLM calls
  # timeout: 180

TOOL_ANALYZE_MODEL:
  provider: qwen
  base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
  model: "qwen-plus"
  api_key: ""
  temperature: 0.2
  token_limit: 200000
  # max_retries: 3 # Maximum number of retries for summary LLM calls
  # timeout: 180

# Use OpenAI ChatGPT for tool generation (Codex replacement)
CODEX_MODEL:
  provider: openai
  base_url: https://api.openai.com/v1
  model: "gpt-4o-mini"
  api_key: "" # or set CODEX_API_KEY / OPENAI_API_KEY
  temperature: 0.2
  max_retries: 3
  timeout: 180